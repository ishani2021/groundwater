{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74efc381-ae83-4767-be36-24ec22dc1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e8ca44-7aeb-4777-95fa-dd4765f990a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44068 entries, 0 to 44067\n",
      "Data columns (total 34 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Id                     44068 non-null  int64  \n",
      " 1   Amount_of_water        44068 non-null  float64\n",
      " 2   Gps_height             44068 non-null  int64  \n",
      " 3   Waterpoint_type        44068 non-null  object \n",
      " 4   Basin_name             44068 non-null  object \n",
      " 5   Village                44068 non-null  object \n",
      " 6   Regionname             44068 non-null  object \n",
      " 7   Region_code            44068 non-null  int64  \n",
      " 8   Wardname               44068 non-null  object \n",
      " 9   District_code          44068 non-null  int64  \n",
      " 10  Population             44068 non-null  int64  \n",
      " 11  Public_meeting         41543 non-null  object \n",
      " 12  Organization_funding   41468 non-null  object \n",
      " 13  Organization_surveyed  44068 non-null  object \n",
      " 14  Scheme_management      41137 non-null  object \n",
      " 15  SchemeName             23117 non-null  object \n",
      " 16  Permit                 41841 non-null  object \n",
      " 17  Company_installed      41465 non-null  object \n",
      " 18  Management             44068 non-null  object \n",
      " 19  Management_group       44068 non-null  object \n",
      " 20  Extraction_type        44068 non-null  object \n",
      " 21  Extraction_type_group  44068 non-null  object \n",
      " 22  Extraction_type_class  44068 non-null  object \n",
      " 23  Payment                44068 non-null  object \n",
      " 24  Payment_type           44068 non-null  object \n",
      " 25  Water_quality          44068 non-null  object \n",
      " 26  Quality_group          44068 non-null  object \n",
      " 27  Quantity               44068 non-null  object \n",
      " 28  Quantity_group         44068 non-null  object \n",
      " 29  Source                 44068 non-null  object \n",
      " 30  Source_type            44068 non-null  object \n",
      " 31  Source_class           44068 non-null  object \n",
      " 32  Waterpoint_type_group  44068 non-null  object \n",
      " 33  Status                 44068 non-null  int64  \n",
      "dtypes: float64(1), int64(6), object(27)\n",
      "memory usage: 11.4+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11015 entries, 0 to 11014\n",
      "Data columns (total 33 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Id                     11015 non-null  int64  \n",
      " 1   Amount_of_water        11015 non-null  float64\n",
      " 2   Gps_height             11015 non-null  int64  \n",
      " 3   Waterpoint_type        11015 non-null  object \n",
      " 4   Basin_name             11015 non-null  object \n",
      " 5   Village                11015 non-null  object \n",
      " 6   Regionname             11015 non-null  object \n",
      " 7   Region_code            11015 non-null  int64  \n",
      " 8   Wardname               11015 non-null  object \n",
      " 9   District_code          11015 non-null  int64  \n",
      " 10  Population             11015 non-null  int64  \n",
      " 11  Public_meeting         10362 non-null  object \n",
      " 12  Organization_funding   11015 non-null  object \n",
      " 13  Organization_surveyed  11015 non-null  object \n",
      " 14  Scheme_management      10291 non-null  object \n",
      " 15  SchemeName             5804 non-null   object \n",
      " 16  Permit                 10486 non-null  object \n",
      " 17  Company_installed      11015 non-null  object \n",
      " 18  Management             11015 non-null  object \n",
      " 19  Management_group       11015 non-null  object \n",
      " 20  Extraction_type        11015 non-null  object \n",
      " 21  Extraction_type_group  11015 non-null  object \n",
      " 22  Extraction_type_class  11015 non-null  object \n",
      " 23  Payment                11015 non-null  object \n",
      " 24  Payment_type           11015 non-null  object \n",
      " 25  Water_quality          11015 non-null  object \n",
      " 26  Quality_group          11015 non-null  object \n",
      " 27  Quantity               11015 non-null  object \n",
      " 28  Quantity_group         11015 non-null  object \n",
      " 29  Source                 11015 non-null  object \n",
      " 30  Source_type            11015 non-null  object \n",
      " 31  Source_class           11015 non-null  object \n",
      " 32  Waterpoint_type_group  11015 non-null  object \n",
      "dtypes: float64(1), int64(5), object(27)\n",
      "memory usage: 2.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_data = pd.read_csv(\"C:\\\\Users\\\\ishan\\\\groundwater\\\\train_data.csv\")\n",
    "test_data = pd.read_csv(\"C:\\\\Users\\\\ishan\\\\groundwater\\\\test_data.csv\")\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(train_data.info())\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea0f18ea-5c0b-46fa-844c-df6f28003d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reduced training data: (44068, 10)\n",
      "Shape of training target: (44068,)\n",
      "Shape of reduced testing data: (11015, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `train_data` and `test_data` are your DataFrames\n",
    "\n",
    "# Specify the important features (including 'Id' for both train and test)\n",
    "important_features = [\n",
    "    'Id', 'Amount_of_water', 'Gps_height', 'Extraction_type', \n",
    "    'Water_quality', 'Quality_group', 'Quantity', \n",
    "    'Source', 'Source_type', 'Source_class', 'Status'\n",
    "]\n",
    "\n",
    "# Select only the important features for training data\n",
    "train_data_important = train_data[important_features]\n",
    "\n",
    "# Separate features and target variable for training data\n",
    "X_train_important = train_data_important.drop(columns=['Status'])\n",
    "y_train_important = train_data_important['Status']\n",
    "\n",
    "# For the test set, remove 'Status' since it's not present in the test data\n",
    "test_important_features = [\n",
    "    'Id', 'Amount_of_water', 'Gps_height', 'Extraction_type', \n",
    "    'Water_quality', 'Quality_group', 'Quantity', \n",
    "    'Source', 'Source_type', 'Source_class'\n",
    "]\n",
    "X_test_important = test_data[test_important_features]\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(f\"Shape of reduced training data: {X_train_important.shape}\")\n",
    "print(f\"Shape of training target: {y_train_important.shape}\")\n",
    "print(f\"Shape of reduced testing data: {X_test_important.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d728c55-68a3-4854-8c23-e36364098cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Handling Missing Values\n",
    "# Let's use SimpleImputer to fill missing values with the mean (for numerical features)\n",
    "# and most frequent value (for categorical features)\n",
    "numerical_features = X_train_important.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X_train_important.select_dtypes(include=['object']).columns\n",
    "\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "categorical_transformer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Step 2: Encoding Categorical Variables\n",
    "# We'll use OneHotEncoder to encode categorical variables\n",
    "# We need to define a pipeline that includes preprocessing and encoding\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_processed = pipeline.fit_transform(X_train_important)\n",
    "X_test_processed = pipeline.transform(X_test_important)\n",
    "\n",
    "# Step 3: Splitting the Data\n",
    "# Split the processed training data into training and validation sets\n",
    "X_train_final, X_valid, y_train_final, y_valid = train_test_split(X_train_processed, y_train_important, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now, your preprocessed data is ready for training your machine learning model\n",
    "# You can use X_train_final, y_train_final for training and X_valid, y_valid for validation\n",
    "# You can use X_test_processed for making predictions on the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda01618-249c-479a-bb52-55ecf2e139c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.77\n",
      "Precision: 0.77\n",
      "Recall: 0.77\n",
      "F1 Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define and fit the logistic regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_logistic = logistic_model.predict(X_valid)\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "accuracy_logistic = accuracy_score(y_valid, y_pred_logistic)\n",
    "precision_logistic = precision_score(y_valid, y_pred_logistic, average='weighted')\n",
    "recall_logistic = recall_score(y_valid, y_pred_logistic, average='weighted')\n",
    "f1_logistic = f1_score(y_valid, y_pred_logistic, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"Accuracy: {accuracy_logistic:.2f}\")\n",
    "print(f\"Precision: {precision_logistic:.2f}\")\n",
    "print(f\"Recall: {recall_logistic:.2f}\")\n",
    "print(f\"F1 Score: {f1_logistic:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64efe86a-0712-4f06-a91d-9b3e26af4546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
